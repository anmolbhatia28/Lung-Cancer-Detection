{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook uses LUNA16 dataset, to train a classifier that classifies a region as nodule or no nodule\n",
    "\n",
    "The luna16 dataset contains several subsets, this notebook requires the subset(num) and location of annotations file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Getting the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions for the function create_data which creates training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_less(num):\n",
    "    if num - 18 < 0:\n",
    "        return num  \n",
    "    else:\n",
    "        return num - 18\n",
    "    \n",
    "def get_patch_from_list(lung_img, coords, window_size = 10):\n",
    "\tshape = lung_img.shape\n",
    "\toutput = []\n",
    "\tlung_img = lung_img + 1024\n",
    "\tfor i in range(len(coords)):\n",
    "\t\tpatch =   lung_img[coords[i][0] - 18: coords[i][0] + 18,\n",
    "\t\t\t\t\t\t   coords[i][1] - 18: coords[i][1] + 18,\n",
    "\t\t\t\t\t\t   coords[i][2] - 18: coords[i][2] + 18]\t\t\t   \n",
    "\t\toutput.append(patch)\n",
    "\treturn output\n",
    "\n",
    "'''\n",
    "Sample a random point from the image and return the coordinates. \n",
    "'''\n",
    "def get_point(shape):\n",
    "\tx = randint(50, shape[2] - 50)\n",
    "\ty = randint(50, shape[1] - 50)\n",
    "\tz = randint(20, shape[0] - 20)\n",
    "\treturn np.asarray([z, y, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "much_data = []\n",
    "def create_data(path, train_csv_path):\n",
    "    coords, trainY = [], []\n",
    "    with open(train_csv_path, 'rb') as f:\n",
    "        lines = f.readlines()\n",
    "        counter = 0\n",
    "        for line in lines:\n",
    "            row = line.decode().split(',')\n",
    "            \n",
    "            all_images = []\n",
    "            all_labels = []\n",
    "            \n",
    "            \n",
    "            if os.path.isfile(path + row[0] + '.mhd') == False:\n",
    "                continue\n",
    "\n",
    "            lung_img = sitk.GetArrayFromImage(sitk.ReadImage(path + row[0] + '.mhd'))\n",
    "\n",
    "            for i in range(-5, 5, 3):\n",
    "                for j in range(-5, 5, 3):\n",
    "                    for k in range(-2, 3, 2):\n",
    "                        coords.append([int(float(row[3])) + k, int(float(row[2])) + j, int(float(row[1])) + i])\n",
    "                        trainY.append(True)\n",
    "                        \n",
    "            for i in range(60):\n",
    "                coords.append(get_point(lung_img.shape))\n",
    "                trainY.append(False)\n",
    "\n",
    "            trainX = get_patch_from_list(lung_img, coords)\n",
    "            \n",
    "\n",
    "            \n",
    "            for elem,x in zip(trainX,trainY):\n",
    "                if elem.shape[0]==36 and elem.shape[1]==36 and elem.shape[2]==36:\n",
    "                    all_images.append(elem)\n",
    "                    all_labels.append(x)\n",
    "            \n",
    "\n",
    "            pickle.dump(np.asarray(all_images), open('./nodules_2/traindata_' + str(counter) + '_Xtrain.p', 'wb'))\n",
    "            pickle.dump(np.asarray(all_labels, dtype = bool),  open('./nodules_2/traindata_' + str(counter) + '_Ytrain.p', 'wb'))\n",
    "\n",
    "            counter = counter + 1\n",
    "            \n",
    "            coords, trainY = [], []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_data('./subset0/', './CSVFILES/annotations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data is created in nodules_2 folder, divide into train and val. After this network is trained. There are 2 classes - nodule or no-nodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import randint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution3D, MaxPooling3D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "'''\n",
    "Creates a keras model with 3D CNNs and returns the model.\n",
    "'''\n",
    "def classifier(input_shape, kernel_size, pool_size):\n",
    "\tmodel = Sequential()\n",
    "\n",
    "\tmodel.add(Convolution3D(16, kernel_size[0], kernel_size[1], kernel_size[2],\n",
    "\t                        border_mode='valid',\n",
    "\t                        input_shape=input_shape, data_format = 'channels_first'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling3D(pool_size=pool_size, data_format = 'channels_first') )\n",
    "\tmodel.add(Convolution3D(32, kernel_size[0], kernel_size[1], kernel_size[2], data_format = 'channels_first'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling3D(pool_size=pool_size, data_format = 'channels_first'))\n",
    "\tmodel.add(Convolution3D(64, kernel_size[0], kernel_size[1], kernel_size[2], data_format = 'channels_first'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling3D(pool_size=pool_size, data_format = 'channels_first'))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(128))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(2))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle,sys\n",
    "import numpy as np\n",
    "from keras.layers.core import Activation, Reshape\n",
    "\n",
    "def train_classifier(input_shape):\n",
    "    val_x = []\n",
    "    val_y = []\n",
    "    model = classifier(input_shape, (3, 3, 3), (2, 2, 2))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "    \n",
    "    for i in range(0,20):\n",
    "        file_name = '/nodules_2/val/traindata_'+str(i)+'_Xtrain.p'\n",
    "        f = open(file_name,'rb')\n",
    "        file_data = pickle.load(f)\n",
    "        \n",
    "        file_name_y = '/nodules_2/val/traindata_'+str(i)+'_Ytrain.p'\n",
    "        f_y = open(file_name_y,'rb')\n",
    "        file_data_y = pickle.load(f_y)\n",
    "        for j in range(len(file_data)):\n",
    "            val_x.append(file_data[j].reshape(1,36,36,36))\n",
    "            #val_y.append(file_data_y[j])\n",
    "            if file_data_y[j] == True:\n",
    "                val_y.append([1,0])\n",
    "            else:\n",
    "                val_y.append([0,1])\n",
    "            \n",
    "    print(np.array(val_x).shape)\n",
    "    print(np.array(val_y).shape)\n",
    "    for i in range(224, 235):\n",
    "        train_x = []\n",
    "        train_y = []\n",
    "        file_name = '/nodules_2/train/traindata_'+str(i)+'_Xtrain.p'\n",
    "        f = open(file_name,'rb')\n",
    "        file_data = pickle.load(f)\n",
    "        \n",
    "        file_name_y = '/nodules_2/train/traindata_'+str(i)+'_Ytrain.p'\n",
    "        f_y = open(file_name_y,'rb')\n",
    "        file_data_y = pickle.load(f_y)\n",
    "        \n",
    "        for j in range(len(file_data)):\n",
    "            #train_x.append(Reshape((36,36,36) + (1,),input_shape = (36,36,36))(np.ndarray.tolist(file_data[j])))\n",
    "            train_x.append(file_data[j].reshape((1,36,36,36)))\n",
    "            if file_data_y[j] == True:\n",
    "                train_y.append([1,0])\n",
    "            else:\n",
    "                train_y.append([0,1])\n",
    "        \n",
    "        #x = Reshape(input_shape + (1, ), input_shape=input_shape)(inputs)\n",
    "        model.train_on_batch(np.array(train_x), np.array(train_y), sample_weight=None)\n",
    "        print('network trained')\n",
    "        \n",
    "        \n",
    "        \n",
    "        val_x = val_x[:108]\n",
    "        for num in range(0,len(val_x),108):\n",
    "            print('accuracy for test is ')\n",
    "            print (model.test_on_batch(np.array(val_x[num:num + 108]), np.array(val_y[num:num+108]), sample_weight=None))\n",
    "        \n",
    "    model.save('/output/model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(16, (3, 3, 3), padding=\"valid\", data_format=\"channels_first\", input_shape=(1, 36, 36...)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18472, 1, 36, 36, 36)\n",
      "(18472,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_4 to have shape (None, 2) but got array with shape (108, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5b620b608c43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m36\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m36\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m36\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-82261c968b4e>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m#x = Reshape(input_shape + (1, ), input_shape=input_shape)(inputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\tensorflow\\lib\\site-packages\\keras-2.0.8-py3.5.egg\\keras\\models.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m    979\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[0;32m    980\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m                                          class_weight=class_weight)\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[1;32mC:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\tensorflow\\lib\\site-packages\\keras-2.0.8-py3.5.egg\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1789\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1790\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1791\u001b[1;33m             check_batch_axis=True)\n\u001b[0m\u001b[0;32m   1792\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1793\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\tensorflow\\lib\\site-packages\\keras-2.0.8-py3.5.egg\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1411\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1412\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1413\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1414\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1415\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32mC:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\tensorflow\\lib\\site-packages\\keras-2.0.8-py3.5.egg\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    152\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m                             str(array.shape))\n\u001b[0m\u001b[0;32m    155\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected activation_4 to have shape (None, 2) but got array with shape (108, 1)"
     ]
    }
   ],
   "source": [
    "train_classifier((1,36,36,36))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
